

## Keywords

AI anxiety, technology realization, rapid change, ethical responsibility, creative empowerment, open source tooling, decentralized networks, hacker edge, AI for good, behavioral science, communication erosion, tribalization, machine war, designer oath, fear management

## Speakers

Speaker 1 (97%), Speaker 2 (3%)

I want to talk about AI anxiety.

Perhaps you're here, perhaps

you're not.

You might be an artist who has not yet reached

this point.

I watch this happen regularly,

which is somebody has a realization the actual power of technology to be able to redeform their environment,

and then they consider some sort of event. So for me, it

happened on a motion capture stage.

I had an event where I had a realization and made me feel very uncomfortable. Ethan Malik calls this, that two days of anxiety in bed is probably reasonable. I tend to agree. I think that this is the correct way that we need to deal with it. You need to sit with your anxiety for a period of time and wrestle with it. So here are some points of advice of how to wrestle with AI anxiety based on own reflections, but also watching others go through it. So the first one is you need to be just come to the realization that this is happening. And coupled with this realization, you need to understand the acceleration of things that are happening, which means that if a discovery happened every decade, it will then happen every year, and then every six months and perhaps every moment, which means that we are having profoundly transformative realizations about the universe on a rapid basis. Okay, not. And so the question is whether these things are right. We are going to a point of whether or not we can fact check these things. And so it could just start creating things, we have no idea of whether or not it's a benefit or not to us, so we're rapidly coming to a point where we're effectively creating magic, but we don't know the dangerous ramifications of it. And I think this has to be reconciled in a way for us to be able to approach it. This is not like your Adobe Photoshop is upgrading a plugin. This is that all software as we know it, and all digital interactions as we know it will completely change, and we have no idea, quite frankly, have no idea, what it's going to look like. So dealing with the first one is speed, the speed of change. As somebody who is a creative who builds things you need to be far, far more adaptable than you are if you have regular processes, regular bureaucratic processes or antiquated processes, things that are very hierarchical or centralized based on your ability to protect you know your your infrastructure security systems, because you're trying to defend against bots and things like that, you are going to evolve much slower than those in the more dangerous sectors that will evolve much, much faster, Right? So when you have open source tooling, localized AI models and lower cost hardware. You're able to set up really advanced technological hubs, collections of computers that have effectively superpowers, right? They can make magical videos. They can make data predictions and analysis. They can render in different ways. They can talk to each other in different ways. They can create value through cryptocurrencies and things like that in a rapid base. So you have worlds, these little worlds that are rapidly forming outside of the safe, structured, slow places. So businesses are going to tend to gravitate to the safe and the whatever. Whereas out in the world these rapidly forming, forming networks of value and AI and open source and who knows what, which is filled with crime and, you know, deep fakes and all these kinds of stuff. However, it is just a wonderland of tools and opportunities and fantastic things. So you gotta live a little bit on the hacker edge, I think, which is that you're gonna need to defend yourself individually and have more grit and more defensive ideas, because you cannot just stay safe in the corporate spaces, you're going to have to force yourself out into more decentralized capacities and interact with networks to find opportunities for you to be able to gain income and survive. So this is also kind of exciting, because you're also taking your opportunity back into your hands. Right before we had a an organizational skew, which meant that we have recruiters, and we had, you know, leads and all these sort of middle management people who just bought into the idea they just wanted a paycheck, right? But very few are leaders and innovators who can step outside and be like, fuck that. I'm gonna go do the thing my own. I'm going to discover what the world can provide me. Look at this AI model. Wow. What opportunities lie in the ability to generate any image that I can possibly think of? What opportunities lie in the ability to create hundreds of millions of characters walking around a planet that I create, right? We're giving you God like powers, right? But you want to go straight to these companies and just serve them as they build this thing. I think you need to go on your own and show them what you can create. This is incredibly powerful, powerful and empowering. The last part of that is means with great power comes great responsibility. There is an ethical challenge that we need to do here, which is, you are going to be able to dictate what happens with this technology. 10 years ago, we taught just a little bit of behavioral science to UX designers, and now we have an entire generation that is addicted and suicidal and all kinds of stuff. Don't tell me, Cambridge Analytica didn't skew prediction networks in our last series of elections. We are losing massive validation within the internet. Our means of communications have eroded. We are fractionalizing. We are tribalizing. We are creating machines of war. The world is going to go into imbalance, and it's up to you as a designer to step in as a creative and seize the opportunities that can put us on the better path. I think every designer should have an ethical responsibility, sort of a Hippocratic Oath, if you would, for designers, and by standing firm that you're able to go forth into this room. Yes, there's fear a doctor has to deal with blood and danger and all kinds of stuff, and the fear of losing people. But if you truly want to help and you want to be part of that as a designer, and you want to design the systems that shape a better world, you should say that you're going to do this for the good of all. AI for good.

## Rate transcript quality