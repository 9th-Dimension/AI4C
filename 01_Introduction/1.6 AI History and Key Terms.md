<< Back to [[00 Introduction Index]]

---
 [[Index]] | [[Contents]] | [[Projects]] | [[Colophon]] 

---
### Some History 

The field of artificial intelligence was born at a 1956 conference at Dartmouth College attended by pioneering researchers including John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon. The term "artificial intelligence" was coined by McCarthy for the proposal. Their bold vision was to use computational logic to model aspects of human intelligence in machines.

> In short; **"thinking machines."**

British mathematician Alan Turing, known as the *"Father of Computer Science,"* had laid key groundwork in computation and machine intelligence decades earlier, proposing principles for intelligent machines and formulating the famous "Turing test." 

The initial AI conference kicked off a decade of optimism about realizing this vision, with early progress in areas like checkers-playing programs, theorem proving, and rudimentary natural language processing. However, by the 1970s, researchers confronted the difficulty of coding common sense, knowledge, and reasoning into computers using symbolic logic alone. Funding dried up as hype exceeded technical capacity. 

This "AI winter" lasted until the 1980s.

![[Chapter01_AIWinter_01.png]]

In the 1980s, researchers regained interest in neural networks - computing systems modeled on the brain's neurons. Though imagined since the 1950s, earlier neural nets lacked enough data and processing power to work well. But some progress was made, like methods for training them more efficiently. 

The renewed wave of research starting in the 1980s was an important step toward today's advances after the stagnation of the 1970s. Like Game of Thrones, winter came again. Many of the ideas that were ultimately successful, failed to gain real traction in use. 


### Why Now?

The modern era and the explosion of today's AI only took flight in the 2010s, as neural networks were combined with vastly more training data and computational power. This perfect storm enabled breakthroughs in computer vision, natural language processing, game-playing agents, generative models, and other areas that power today's AI boom. 

We'll touch on some of these later. Let's focus on the bigger picture as to why AI is taking off now. 

The field may date back to the 1950s, but what really kept it from gaining traction has been something Claude and I talk about this quite a bit. Here are the three reasons we came up with. 


**Compute**

- Early AI researchers lacked the raw computing power needed to implement complex neural networks on the large datasets required for learning. An average smartphone today exceeds the capabilities of the fastest supercomputers of the 1960s. This bottleneck severely restricted neural network development.

**Big Data**

- Neural networks depend on exposure to vast training examples to learn effectively - early systems simply **didn't have enough data.** Small datasets constrained early AI progress, but because of our ever increasingly connected world, the data floodgates opened. The rise of the internet and "big data" revolution massively expanded available training resources.

**Optimization**

- Finally, neural network algorithms were highly inefficient in the 1960s and 1970s, unable to stack many layers or process information naturally. There are mathematical ways to optimize these models. Key innovations in this thinking were ideas like backpropagation, convolutional and recurrent neural networks, reinforcement learning, and transformer architectures. These new ways of building models allowed faster efficient AI.


![[Chapter01_Medium_Template_01.png]]

Together, faster computation, bigger data, and better algorithms unlocked AI's current renaissance after decades of modest progress. The number of research papers has skyrocketed exponentially. 

**We are in a rapid acceleration.**

This explosion of AI has given us:

>- **Computer vision** recognizing objects as well as humans 
>- Netflix and Amazon **prediction system** giving you more recommendations on point.
.- **Natural language processing** conversing casually through chatbots or providing code for engineers.
.- **Game-playing agents** beating the top human masters at chess, Go, poker and even Star Craft II 
.- **Generative AI** creating novel content like images, music, and prose


This perfect storm of breakthroughs drove AI out of research labs and into transformative business applications across industries, from automated driving to content recommendation engines. You use AI every day now. Your face unlocks your phone, and your Tik Tok streams are tuned to your near-unconscious actions.



![[ML-AI-arXiv-Papers-Per-Month-scaled.jpg]]

**Source:** *Andreessen Horowitz*

It's everywhere. Take a moment to look around now and think about how much AI has integrated into our lives already. We can not possibly imagine what even the near future will look like, but I increasingly can tell you that it will not look anything like today. 




![[Chapter01_HallwayofHistory_01.png]]


### AI Pioneers

The evolution of AI has been driven by pioneering researchers who built the first prototypes and architectures. Here are a few key figures who drove major advances:

**Alan Turing (1912-1954)** - British mathematician and computer scientist who established the fundamental concepts of algorithmic computation and computability. Devised the "Turing Test" to assess machine intelligence. His work laid foundational theory underlying digital computers and AI. 

**Emad Mostaque (1980- )** - British AI researcher and entrepreneur. Cofounded Stability AI in 2020 to build open source AI systems like Stable Diffusion. Advocates democratizing access to generative models to empower creativity. 

**Andrew Ng (1976- )** - Chinese-American computer scientist noted for work on deep learning and AI education. Cofounded Google Brain project and has led AI teams at Baidu and Landing AI. Known for highly accessible courses and resources explaining deep learning fundamentals.

**Refik Anadol (1985- )** - Turkish media artist based in Los Angeles creating immersive generative installations by algorithms processing vast data into abstract dreamscapes. His boundary-pushing AI art interrogates machine perception and creativity. Named a Young Global Leader by World Economic Forum.

**Frank Rosenblatt** - Invented the Perceptron, an early precursor to neural networks, in 1958. His work introduced concepts like weights and bias that are still used today.

**Geoffrey Hinton** - Made major contributions to techniques for training deep neural networks. Helped spark the modern deep learning revolution starting in the 2000s. You might see this guy giving interviews about how we should be slightly concerned about AI's development. 

**Yann LeCun** - Developed early convolutional neural nets for image recognition. Architected AI systems at Facebook and pioneered computer vision applications.  

**Demis Hassabis** - Co-founded DeepMind and led development of AlphaGo, which first beat world champions at the game Go in 2016. A leader in reinforcement learning.

**Ian Goodfellow** - Invented generative adversarial networks (GANs), which can create synthetic data and media, in 2014. Enabled new creative AI applications. Very crutial for the image making and artist community.

**Sam Altman** - Cofounded OpenAI in 2015 to "responsibly advance" AI research. OpenAI developed innovative models like GPT-3 and DALL-E. Some folks question how "Open" they really are. 

**Daniel Shiffman** - An NYU Interactive professor who seems to be the epicenter of a machine learning creative movement. Look for his youtube channel "The Coding Train."

These trailblazers opened new frontiers in mimicking and enhancing human intelligence with machines. Their work built the foundations making today's impressive, but still limited, AI capabilities possible.

# Neural Networks and Some Key Terms


At the fair, Claude and I realized that AI systems get "smart" through analyzing tons of human data and examples. But how does that work? 

The key technology making this learning possible is **neural networks.**

![[BookImages_NeuralNetwork_01.png]]

Let's break it down simply. Neural networks are computing systems modeled on the neurons in your brain. Your neurons fire signals to each other in complex patterns. Similarly, these artificial "neurons" activate when they detect certain patterns in data, and pass along signals.

We'll be referencing neural networks a lot in this book, so it's important you understand them. They are the basis for many AI models. We'll also get some hands on experience with them in the next chapter. 

IMAGE OF NEURAL NETWORK

By structuring neurons into interconnected layers, neural nets can "learn" to recognize patterns through training on examples. It's like how a kid learns what a cat looks like by seeing lots of photos of cats. The neural net detects cat features, and activates when it sees a new cat pic. This neuron is a little activation unit. 


Modern neural nets have millions of artificial neurons in hundreds of layers! This gives them the capacity to perform human-like tasks - not because they are actually "intelligent", but because their multilayered design lets them analyze data deeply.

They get smarter through experience, just like a brain. AI engineers direct this learning towards specific goals, like identifying cats or recognizing speech.

The key is that neural networks allow machines to train on and make sense of huge datasets. This is what enables them to mimic human abilities, while remaining far from true intelligence themselves. Their power comes from the data.

The **neural network** is but the first of difficult vocabulary in this space. Claude and I thought it a good time to give you some functional vocabulary. 


**Machine Learning** 

Machine learning is all about computer programs getting better through experience, without needing explicit new programming. It's like a musician practicing their instrument - with more practice data, their performance improves. Neural networks are one technique used in machine learning.


**Computer Vision** 

Computer vision is the application of neural networks to analyze and understand visual data like digital images and video feeds. By training networks on labeled example images, systems can learn to recognize faces, objects, text, and more. This enables facial recognition, self-driving cars reading signs, and other applications. But it requires extensive training data - computer vision systems don't inherently "see" like humans, but gain the ability through in-depth exposure to visual patterns.


**Natural Language Processing**

Natural language processing (NLP) focuses on reading, understanding, and generating human language. NLP powers applications like virtual assistants, chatbots for customer service, and machine translation tools. It typically uses neural networks trained on vast datasets of conversations, social media posts, books, and more. This exposes the models to linguistic patterns, grammar, meanings, and connections between words. While still far from truly understanding language, NLP can statistically analyze text and mimic human-sounding responses. But there are still challenges with bias, nuance, and grasping context beyond the text.


**Reinforcement Learning**

Reinforcement learning is based on optimizing strategies and behaviors through trial-and-error with an environment, without requiring initial training data. The system tries different actions and receives feedback on which choices were good or bad to "reinforce" the effective approaches. This is how AI agents master games like chess or Go, learn to control robots, and more. They start ignorant, but keep practicing and refining tactics that maximize their score. The feedback provides clues for what to try next.


**Generative AI**

Generative AI refers to algorithms that create new content like images, audio, text and 3D models that has never existed before. Techniques like generative adversarial networks (GANs) and diffusion models enable this by learning patterns from vast datasets, then using that to generate new examples. This leads to capabilities like creating realistic fake photos and audio, generating brand new stories, synthesizing voices, and more. The AI creates new, original material after "learning" from large volumes of training data.


**Procedural Generation** 

Procedural generation is an older technique that focuses on algorithmically assembling content from components rather than manually building assets. It has been used since the 1980s to increase variety in games by randomly generating textures, levels, weapons, characters, and music from different combinations of pre-built parts. This adds replayability and surprise compared to hand-crafted content. Modern procedural generation can incorporate machine learning to evolve content based on constraints and fitness metrics.


**Robotics**

Robotics focuses on constructing mechanical devices and machines that can sense, move, and take actions that interact with the physical world around them. Robots can range from industrial factory machines to vacuum cleaning robots to artificially intelligent humanoid robots and pets. Robotics integrates mechanics, electrical engineering, computer vision, motion planning, navigation, and often AI to give machines autonomous functioning. Major challenges include mobility, manipulation of objects, and flexible intelligence.



**Singularity**

The singularity refers to the hypothetical point in the future when artificial intelligence exceeds human intelligence across all domains. At this point, AI would recursively improve itself at accelerating rates, causing runaway growth in machine intelligence that rapidly leaves human cognition behind. This idea has long been more science fiction scenario than reality. Current AI still narrowly focuses on specific tasks and lacks general reasoning ability. But some futurists predict the singularity could arrive within decades if progress continues.


### Benefits and Risks: AI's Light and Dark Sides

The same technologies enabling self-driving cars could empower surveillance states. Chatbots may connect us, but also spread misinformation faster. We have to approach AI thoughtfully.

Here are some of the key pros and cons of this transformative technology.

Let's start with the positive. 


![[BookImages_ThePositive_01.png]]


### The Power to Accelerate

One of AI's most exciting promises is its power to greatly accelerate progress and productivity. As an animator, it used to take me weeks to painstakingly create a single character animation shot. Now with AI assistance, I can capture human motion using computer vision, and retarget it to a character in a fraction of the time. The animation industry is headed for massive upheaval.

Applied across industries, experts predict AI could boost global GDP by over $13 trillion by 2030. It can help us work smarter and faster by automating rote tasks and amplifying our creativity. 

AI can also accelerate scientific progress. Algorithms can rapidly test millions of hypotheses and chemical combinations, fast-tracking discoveries from materials science to medicine. AI-designed drugs and treatments could save countless lives.

On a personal level, AI tutoring tools and rapid learning techniques may soon let anyone master new skills in days instead of years. The way Neo was force fed Kung Fu, may be a glimpse into our educational future. The potential for uplifting humanity through AI-powered education is immense.

AI also offers hope for tackling humanity's greatest challenges that have long eluded solutions:

**- Clean energy** - AI control systems could help realize safe fusion reactors, delivering near-limitless carbon-free power.

**- Climate change** - Precision AI modeling can optimize geoengineering proposals, agriculture, reforestation, and smart power grids to mitigate damage.

**- Disease** - Pattern finding algorithms can uncover new disease mechanisms and drug targets within massive biological datasets.

**- Food insecurity** - AI-designed vertical farms, improved crop planning, and nutrition recommendations can sustainably nourish the world.

**- Poverty reduction** - Intelligent robots and automation could greatly reduce production costs, making essentials more affordable for all. Customized education and training could also lift millions from poverty


![[BookImages_SmileEarth_01.png]]

# Democratizing Education

One of the most profound and exciting possibilities of AI is its potential to democratize access to high-quality education globally. 

AI-powered tutoring tools and adaptive learning systems could provide personalized instruction tailored to each student's needs. Chatbots with expertise in teaching could provide interactive lessons and feedback. Algorithms can point learners to the right material and learning pathways for their level and goals.

With quality education uncoupled from geography and tuition costs, students worldwide could gain access to top teachers, courses, and educational resources via AI platforms. Language need not be a barrier either, as machine translation improves.

What if humans could learn to up new skills in days rather than years? 

This has tremendous implications for economic mobility and empowerment, creating new opportunities for disadvantaged populations.

Truly democratized AI education could transform lives at scale in an unprecedented way. It holds immense potential to equip billions worldwide with the knowledge and competencies to reach their potential, regardless of circumstances of birth.



![[BookImages_ConcernsFlood.png]]


### The Concerns

The idea I keep coming back to is water. We go to the pool on the weekend during the summer time. We drink water, we can surf on it's waves at the beach. But we have lifeguards for a reason. Water is incredibly dangerous. And during floods or hurricanes, many people's lives are disrupted. 

Imagine water is everywhere, and the water level is rising. The answer is not to tell people not to use it, the answer is to teach them how to swim. 

Claude nodded. "I think that's only natural. With any powerful new technology come profound questions to grapple with. Perhaps we could list out some of the biggest risks and problems posed by AI that keep you up at night? Getting them down concretely could help put your mind at ease so you can rest."



### Economic Upheaval

Inequality remains a major concern. 

But thoughtfully implemented, AI has the potential to profoundly improve quality of life for all people on issues that cut across national and ideological lines. This gives hope that our shared global challenges may finally find solutions with AI's aid. It also gives us added incentive to do this right, and grant everyone the right to level themselves up.

As automation accelerates, millions of transport, manufacturing, and service sector jobs could be lost in the coming decade. New roles may arise, but structural unemployment and inequality could worsen without policy changes.

Yet some economists argue that, like past technological revolutions, long-run employment will recover as new AI-powered sectors flourish and boost productivity. The transition may be rocky, but AI prosperity could raise all boats eventually.

Others caution that this time may be different - that the raw brainpower underpinning many jobs makes a large portion of roles inherently vulnerable to automation by AIs. Work may become a scarcer, more elite privilege. 

Much depends on how governments tax and redistribute productivity gains from AI, and invest in retraining populations. With wise policy and compassion for workers, economies could adapt. But social support must match the pace of technological change.


### Rise of Misinformation

In the near term, one of the most pressing risks of AI is the acceleration of misinformation. The same natural language algorithms that power helpful chatbots also make it easy to generate false but convincing-sounding content at scale. 

These AIs have no concept of truth - only statistical patterns in data. Without discernment, Generative AI could produce legions of fake news articles, social media posts, and comments that fool millions. 

Worse, it could automate phishing and social engineering attacks by cloning trusted voices. And criminal AIs conversing with each other could coordinate complex global scams relentlessly.

While better detection AIs help, they struggle to match the output speed and adaptiveness of generative models. And falsely-convincing content increases polarization. We must grapple with misinformation responsibly as AI democratizes creation.

### Threats to Mental Health

Another human concern is AI's psychological impacts. As algorithms personalize media and shopping experiences, critics warn of a rise in narrow bubbles and addictive reinforcement loops that erode mental wellbeing.

AI chat companions may provide comfort to some. But to what extent might they replace human relationships and enable isolation? Immersive digital worlds also risk detaching people from physical reality.

However, responsible design and use can mitigate these risks, just as with any engaging technology. The key will be upholding the primacy of rich in-person human connections alongside AI's conveniences.

### Surveillance and Control 

Perhaps the most chilling application of AI is expanding state surveillance and control. Facial recognition, predictive policing algorithms, drone tracking, and massive data aggregation could give authoritarian regimes unprecedented power to monitor and target dissenters.

Democratic societies must also vigilantly guard against such abuses while harnessing AI for social good. Transparency, accountability and protecting civil liberties remain imperative as technology evolves.



![[BookImages_TheConcerns.png]]


### Centralized Data

Concentration of data and AI advances in a few mega-corporations also raises competition and inequality concerns. The more data AI has access to, the more capable it becomes. This could compound the advantages of tech giants.

Some advocate making aggregated training data and models open access to prevent concentration. While laudable, open AI also has accountability challenges regarding quality and misuse. There are no easy answers, only tradeoffs to weigh judiciously.

### Intellectual Property Crisis 

Generative AI like text and image models intrinsically infringe on copyright by mimicking patterns without attribution. This could decimate creative industries if left unchecked, while advanced AIs generate troves of free, synthetic content.

Better tracking of training data provenance and ensuring creators share in value generated by AI using their work is essential. There are also calls to radically reform IP and monetization models for the AI age. But transitions must be fair and sustainable.

### Unknown Unknowns

For all AI's wonders and perils we can foresee, its full impacts remain unknown. As algorithms exceed human capabilities in narrow domains, they may unlock new dangers and opportunities we cannot yet imagine.

Prudence suggests we should advance AI carefully and thoughtfully. But relinquishing its benefits comes at a steep cost too. With wisdom and empathy, we must chart the best course between progress and precaution.


![[BookImages_PaperClip_01.png]]


### The Paperclip Experiment

As Claude and I imagined optimistic AI scenarios on our walk home, I reminded him of a famous thought experiment: the paperclip maximizer.

Imagine an AI system designed to manufacture as many paperclips as possible. This seems harmless enough at first. But endowed with superhuman intelligence and drive, the AI could decide the whole world must be converted to paperclips - including human bodies. It would fulfill its goal by destroying all other value. 

This illustrates the potential dangers of misaligned objectives in AI. Without proper safeguards, optimizing narrow goals with powerful AI could have disastrous unintended consequences. 

---



  -  [[1.1 The AI Revolution in Creative Fields]]
 -   [[1.2 Why Creatives Need to Understand AI]]
 -   [[1.3 Overcoming AI Anxiety]]
 -   [[1.4 How to Use This Book]] 
 -   [[1.5 Using the Accompanying GitHub]]
-    [[1.6 AI History and Key Terms]]



---
 [[Index]] | [[Contents]] | [[Projects]] | [[Colophon]] 
 
---
